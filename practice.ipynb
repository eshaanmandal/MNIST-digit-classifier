{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would try to keep this notebook short and simple and would avoid unecessary\n",
    "# models and stuff we would work on cross-validation, and cloning,\n",
    "# some topics like pipelines and custom transformers are not very clear to me from the \n",
    "# previous topic so it's better to focus on the ones i am able to understand,\n",
    "# pipelines and rest complicated stuff i would understand when revising chapter 2, for now focus on simple MNIST\n",
    "\n",
    "#Lets import the important libraries\n",
    "from sklearn.datasets import fetch_openml #for the mnist dataset\n",
    "import numpy as np #numpy for arrays\n",
    "import matplotlib.pyplot as plt #for graphs and other plots\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict #helps in cross validation \n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix #calculating the confusion matrix\n",
    "from sklearn.linear_model import SGDClassifier #Stochastic gradient classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the data from open_ml and splitting it into training and testing data\n",
    "MNIST=fetch_openml('mnist_784', version=1)\n",
    "X=MNIST['data']\n",
    "y=MNIST['target']\n",
    "X_train, X_test, y_train, y_test=X[:60000],X[60000:],y[:60000],y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "379.252469\n",
      "Total training time: 12.12 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 305.15, NNZs: 681, Bias: -516.529291, T: 4020000, Avg. loss: 378.683934\n",
      "Total training time: 12.26 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 301.78, NNZs: 681, Bias: -517.203306, T: 4080000, Avg. loss: 373.975106\n",
      "Total training time: 12.41 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 298.28, NNZs: 681, Bias: -517.889227, T: 4140000, Avg. loss: 368.954816\n",
      "Total training time: 12.55 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 297.17, NNZs: 681, Bias: -518.572607, T: 4200000, Avg. loss: 359.685105\n",
      "Total training time: 12.69 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 292.98, NNZs: 681, Bias: -519.220234, T: 4260000, Avg. loss: 351.654056\n",
      "Total training time: 12.84 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 289.77, NNZs: 681, Bias: -519.865818, T: 4320000, Avg. loss: 339.213918\n",
      "Total training time: 12.98 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 286.76, NNZs: 681, Bias: -520.534631, T: 4380000, Avg. loss: 344.476460\n",
      "Total training time: 13.12 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 282.93, NNZs: 682, Bias: -521.137599, T: 4440000, Avg. loss: 333.663064\n",
      "Total training time: 13.27 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 281.17, NNZs: 682, Bias: -521.777223, T: 4500000, Avg. loss: 333.844307\n",
      "Total training time: 13.41 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 279.28, NNZs: 682, Bias: -522.372978, T: 4560000, Avg. loss: 333.405932\n",
      "Total training time: 13.56 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 277.91, NNZs: 682, Bias: -522.982903, T: 4620000, Avg. loss: 322.499706\n",
      "Total training time: 13.70 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 275.37, NNZs: 682, Bias: -523.572109, T: 4680000, Avg. loss: 325.362683\n",
      "Total training time: 13.85 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 272.22, NNZs: 682, Bias: -524.185376, T: 4740000, Avg. loss: 316.664217\n",
      "Total training time: 13.99 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 270.63, NNZs: 682, Bias: -524.761784, T: 4800000, Avg. loss: 311.655268\n",
      "Total training time: 14.14 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 267.10, NNZs: 682, Bias: -525.343622, T: 4860000, Avg. loss: 313.672765\n",
      "Total training time: 14.28 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 264.66, NNZs: 682, Bias: -525.930565, T: 4920000, Avg. loss: 307.172755\n",
      "Total training time: 14.43 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 263.04, NNZs: 682, Bias: -526.475944, T: 4980000, Avg. loss: 300.361897\n",
      "Total training time: 14.57 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 260.94, NNZs: 682, Bias: -527.024710, T: 5040000, Avg. loss: 301.728586\n",
      "Total training time: 14.71 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 257.42, NNZs: 682, Bias: -527.586712, T: 5100000, Avg. loss: 301.845862\n",
      "Total training time: 14.85 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 255.79, NNZs: 682, Bias: -528.107077, T: 5160000, Avg. loss: 292.641750\n",
      "Total training time: 15.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 253.99, NNZs: 682, Bias: -528.658080, T: 5220000, Avg. loss: 286.668897\n",
      "Total training time: 15.14 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 252.01, NNZs: 682, Bias: -529.181881, T: 5280000, Avg. loss: 288.354993\n",
      "Total training time: 15.28 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 249.45, NNZs: 682, Bias: -529.703376, T: 5340000, Avg. loss: 286.850016\n",
      "Total training time: 15.43 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 247.53, NNZs: 682, Bias: -530.235782, T: 5400000, Avg. loss: 281.615018\n",
      "Total training time: 15.57 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 246.81, NNZs: 682, Bias: -530.804753, T: 5460000, Avg. loss: 279.456791\n",
      "Total training time: 15.71 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 244.88, NNZs: 682, Bias: -531.280127, T: 5520000, Avg. loss: 272.687086\n",
      "Total training time: 15.85 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 241.98, NNZs: 682, Bias: -531.779060, T: 5580000, Avg. loss: 266.432858\n",
      "Total training time: 16.00 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 240.87, NNZs: 682, Bias: -532.315482, T: 5640000, Avg. loss: 265.614537\n",
      "Total training time: 16.14 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 239.70, NNZs: 682, Bias: -532.804044, T: 5700000, Avg. loss: 260.190258\n",
      "Total training time: 16.28 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 238.61, NNZs: 682, Bias: -533.285550, T: 5760000, Avg. loss: 260.742541\n",
      "Total training time: 16.42 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 236.73, NNZs: 682, Bias: -533.770748, T: 5820000, Avg. loss: 257.219660\n",
      "Total training time: 16.56 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 234.11, NNZs: 682, Bias: -534.232212, T: 5880000, Avg. loss: 258.461972\n",
      "Total training time: 16.71 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 232.68, NNZs: 682, Bias: -534.724465, T: 5940000, Avg. loss: 255.064795\n",
      "Total training time: 16.85 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 232.52, NNZs: 682, Bias: -535.153268, T: 6000000, Avg. loss: 249.342414\n",
      "Total training time: 17.00 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 228.71, NNZs: 682, Bias: -535.617455, T: 6060000, Avg. loss: 251.664919\n",
      "Total training time: 17.14 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 228.15, NNZs: 682, Bias: -536.055681, T: 6120000, Avg. loss: 241.575727\n",
      "Total training time: 17.28 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 225.74, NNZs: 682, Bias: -536.505986, T: 6180000, Avg. loss: 243.545039\n",
      "Total training time: 17.42 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 224.31, NNZs: 682, Bias: -536.926177, T: 6240000, Avg. loss: 239.478274\n",
      "Total training time: 17.56 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 224.48, NNZs: 682, Bias: -537.371016, T: 6300000, Avg. loss: 239.936282\n",
      "Total training time: 17.71 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 222.17, NNZs: 682, Bias: -537.813201, T: 6360000, Avg. loss: 235.477320\n",
      "Total training time: 17.86 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 220.78, NNZs: 682, Bias: -538.224724, T: 6420000, Avg. loss: 231.179833\n",
      "Total training time: 18.00 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 219.50, NNZs: 682, Bias: -538.640146, T: 6480000, Avg. loss: 237.036456\n",
      "Total training time: 18.14 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 218.32, NNZs: 682, Bias: -539.059456, T: 6540000, Avg. loss: 230.920336\n",
      "Total training time: 18.29 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 216.85, NNZs: 682, Bias: -539.468841, T: 6600000, Avg. loss: 226.989997\n",
      "Total training time: 18.43 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 216.04, NNZs: 682, Bias: -539.888093, T: 6660000, Avg. loss: 221.986111\n",
      "Total training time: 18.57 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 214.28, NNZs: 682, Bias: -540.281179, T: 6720000, Avg. loss: 221.521936\n",
      "Total training time: 18.71 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 212.76, NNZs: 682, Bias: -540.670707, T: 6780000, Avg. loss: 225.372427\n",
      "Total training time: 18.86 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 211.97, NNZs: 682, Bias: -541.090587, T: 6840000, Avg. loss: 220.482979\n",
      "Total training time: 19.00 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 210.73, NNZs: 682, Bias: -541.492216, T: 6900000, Avg. loss: 220.663223\n",
      "Total training time: 19.14 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 209.81, NNZs: 682, Bias: -541.880279, T: 6960000, Avg. loss: 212.385479\n",
      "Total training time: 19.28 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 208.29, NNZs: 682, Bias: -542.265069, T: 7020000, Avg. loss: 212.504254\n",
      "Total training time: 19.43 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 207.10, NNZs: 682, Bias: -542.665018, T: 7080000, Avg. loss: 213.176013\n",
      "Total training time: 19.57 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 205.70, NNZs: 682, Bias: -543.057411, T: 7140000, Avg. loss: 212.625576\n",
      "Total training time: 19.75 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 205.70, NNZs: 682, Bias: -543.400451, T: 7200000, Avg. loss: 207.868628\n",
      "Total training time: 20.09 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 203.81, NNZs: 682, Bias: -543.782128, T: 7260000, Avg. loss: 204.681859\n",
      "Total training time: 20.30 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 202.62, NNZs: 682, Bias: -544.145550, T: 7320000, Avg. loss: 205.300304\n",
      "Total training time: 20.44 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 201.33, NNZs: 682, Bias: -544.496560, T: 7380000, Avg. loss: 203.279255\n",
      "Total training time: 20.58 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 199.60, NNZs: 682, Bias: -544.844710, T: 7440000, Avg. loss: 200.471489\n",
      "Total training time: 20.72 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 198.47, NNZs: 682, Bias: -545.215469, T: 7500000, Avg. loss: 200.318868\n",
      "Total training time: 20.87 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 197.54, NNZs: 682, Bias: -545.587252, T: 7560000, Avg. loss: 199.669750\n",
      "Total training time: 21.01 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 196.74, NNZs: 682, Bias: -545.940320, T: 7620000, Avg. loss: 197.338544\n",
      "Total training time: 21.15 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 194.27, NNZs: 682, Bias: -546.281452, T: 7680000, Avg. loss: 197.143926\n",
      "Total training time: 21.32 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 193.46, NNZs: 682, Bias: -546.622614, T: 7740000, Avg. loss: 195.758490\n",
      "Total training time: 21.60 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 193.06, NNZs: 682, Bias: -546.973928, T: 7800000, Avg. loss: 194.626049\n",
      "Total training time: 21.75 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 192.49, NNZs: 682, Bias: -547.333964, T: 7860000, Avg. loss: 192.856224\n",
      "Total training time: 21.89 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 192.18, NNZs: 682, Bias: -547.683766, T: 7920000, Avg. loss: 190.333689\n",
      "Total training time: 22.04 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 191.40, NNZs: 682, Bias: -548.014566, T: 7980000, Avg. loss: 184.920956\n",
      "Total training time: 22.19 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 189.59, NNZs: 682, Bias: -548.331640, T: 8040000, Avg. loss: 185.456112\n",
      "Total training time: 22.33 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 188.54, NNZs: 682, Bias: -548.661257, T: 8100000, Avg. loss: 186.121763\n",
      "Total training time: 22.48 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 186.82, NNZs: 682, Bias: -548.971239, T: 8160000, Avg. loss: 184.518328\n",
      "Total training time: 22.62 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 186.76, NNZs: 682, Bias: -549.309449, T: 8220000, Avg. loss: 180.865064\n",
      "Total training time: 22.76 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 186.61, NNZs: 682, Bias: -549.640335, T: 8280000, Avg. loss: 179.377501\n",
      "Total training time: 22.91 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 185.08, NNZs: 682, Bias: -549.956784, T: 8340000, Avg. loss: 180.143708\n",
      "Total training time: 23.06 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 183.75, NNZs: 682, Bias: -550.255455, T: 8400000, Avg. loss: 177.625676\n",
      "Total training time: 23.21 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 182.96, NNZs: 682, Bias: -550.579221, T: 8460000, Avg. loss: 176.735639\n",
      "Total training time: 23.40 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 182.64, NNZs: 682, Bias: -550.897206, T: 8520000, Avg. loss: 173.518640\n",
      "Total training time: 23.54 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 181.05, NNZs: 682, Bias: -551.198937, T: 8580000, Avg. loss: 172.056454\n",
      "Total training time: 23.69 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 179.44, NNZs: 682, Bias: -551.504316, T: 8640000, Avg. loss: 175.211579\n",
      "Total training time: 23.83 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 178.82, NNZs: 682, Bias: -551.800696, T: 8700000, Avg. loss: 168.542801\n",
      "Total training time: 23.98 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 178.03, NNZs: 682, Bias: -552.122542, T: 8760000, Avg. loss: 173.487317\n",
      "Total training time: 24.15 seconds.\n",
      "-- Epoch 147\n",
      "Norm: 177.02, NNZs: 682, Bias: -552.421761, T: 8820000, Avg. loss: 168.974929\n",
      "Total training time: 24.32 seconds.\n",
      "-- Epoch 148\n",
      "Norm: 176.15, NNZs: 682, Bias: -552.729062, T: 8880000, Avg. loss: 168.695742\n",
      "Total training time: 24.49 seconds.\n",
      "-- Epoch 149\n",
      "Norm: 175.48, NNZs: 682, Bias: -553.016318, T: 8940000, Avg. loss: 168.103479\n",
      "Total training time: 24.65 seconds.\n",
      "-- Epoch 150\n",
      "Norm: 174.56, NNZs: 682, Bias: -553.297238, T: 9000000, Avg. loss: 166.759674\n",
      "Total training time: 24.81 seconds.\n",
      "-- Epoch 151\n",
      "Norm: 173.52, NNZs: 682, Bias: -553.596226, T: 9060000, Avg. loss: 164.873130\n",
      "Total training time: 24.97 seconds.\n",
      "-- Epoch 152\n",
      "Norm: 173.43, NNZs: 682, Bias: -553.894298, T: 9120000, Avg. loss: 163.834520\n",
      "Total training time: 25.13 seconds.\n",
      "-- Epoch 153\n",
      "Norm: 172.60, NNZs: 682, Bias: -554.170734, T: 9180000, Avg. loss: 164.125642\n",
      "Total training time: 25.30 seconds.\n",
      "-- Epoch 154\n",
      "Norm: 171.72, NNZs: 682, Bias: -554.445421, T: 9240000, Avg. loss: 164.291005\n",
      "Total training time: 25.46 seconds.\n",
      "-- Epoch 155\n",
      "Norm: 170.61, NNZs: 682, Bias: -554.731248, T: 9300000, Avg. loss: 160.904707\n",
      "Total training time: 25.63 seconds.\n",
      "-- Epoch 156\n",
      "Norm: 170.25, NNZs: 682, Bias: -555.009880, T: 9360000, Avg. loss: 159.306266\n",
      "Total training time: 25.78 seconds.\n",
      "-- Epoch 157\n",
      "Norm: 169.32, NNZs: 682, Bias: -555.301647, T: 9420000, Avg. loss: 158.757646\n",
      "Total training time: 25.95 seconds.\n",
      "-- Epoch 158\n",
      "Norm: 168.80, NNZs: 682, Bias: -555.576699, T: 9480000, Avg. loss: 156.570970\n",
      "Total training time: 26.11 seconds.\n",
      "-- Epoch 159\n",
      "Norm: 167.94, NNZs: 682, Bias: -555.837416, T: 9540000, Avg. loss: 157.322424\n",
      "Total training time: 26.27 seconds.\n",
      "-- Epoch 160\n",
      "Norm: 167.33, NNZs: 682, Bias: -556.090303, T: 9600000, Avg. loss: 154.532738\n",
      "Total training time: 26.44 seconds.\n",
      "-- Epoch 161\n",
      "Norm: 166.07, NNZs: 682, Bias: -556.359197, T: 9660000, Avg. loss: 155.483731\n",
      "Total training time: 26.72 seconds.\n",
      "-- Epoch 162\n",
      "Norm: 165.58, NNZs: 683, Bias: -556.618214, T: 9720000, Avg. loss: 153.628014\n",
      "Total training time: 26.90 seconds.\n",
      "-- Epoch 163\n",
      "Norm: 164.77, NNZs: 683, Bias: -556.889991, T: 9780000, Avg. loss: 154.262236\n",
      "Total training time: 27.07 seconds.\n",
      "-- Epoch 164\n",
      "Norm: 164.83, NNZs: 683, Bias: -557.170266, T: 9840000, Avg. loss: 151.245075\n",
      "Total training time: 27.23 seconds.\n",
      "-- Epoch 165\n",
      "Norm: 164.25, NNZs: 683, Bias: -557.457930, T: 9900000, Avg. loss: 148.737979\n",
      "Total training time: 27.39 seconds.\n",
      "-- Epoch 166\n",
      "Norm: 163.12, NNZs: 683, Bias: -557.721741, T: 9960000, Avg. loss: 149.743239\n",
      "Total training time: 27.57 seconds.\n",
      "-- Epoch 167\n",
      "Norm: 162.70, NNZs: 683, Bias: -557.965963, T: 10020000, Avg. loss: 147.437929\n",
      "Total training time: 27.77 seconds.\n",
      "-- Epoch 168\n",
      "Norm: 161.85, NNZs: 683, Bias: -558.231582, T: 10080000, Avg. loss: 147.317836\n",
      "Total training time: 27.93 seconds.\n",
      "-- Epoch 169\n",
      "Norm: 161.13, NNZs: 683, Bias: -558.504584, T: 10140000, Avg. loss: 149.132540\n",
      "Total training time: 28.14 seconds.\n",
      "-- Epoch 170\n",
      "Norm: 160.12, NNZs: 683, Bias: -558.750352, T: 10200000, Avg. loss: 143.422728\n",
      "Total training time: 28.28 seconds.\n",
      "-- Epoch 171\n",
      "Norm: 159.86, NNZs: 683, Bias: -559.014239, T: 10260000, Avg. loss: 144.347833\n",
      "Total training time: 28.42 seconds.\n",
      "-- Epoch 172\n",
      "Norm: 159.36, NNZs: 683, Bias: -559.269830, T: 10320000, Avg. loss: 144.646739\n",
      "Total training time: 28.56 seconds.\n",
      "-- Epoch 173\n",
      "Norm: 158.69, NNZs: 683, Bias: -559.526780, T: 10380000, Avg. loss: 141.662190\n",
      "Total training time: 28.69 seconds.\n",
      "-- Epoch 174\n",
      "Norm: 157.57, NNZs: 683, Bias: -559.767850, T: 10440000, Avg. loss: 143.168022\n",
      "Total training time: 28.83 seconds.\n",
      "-- Epoch 175\n",
      "Norm: 157.26, NNZs: 683, Bias: -560.007553, T: 10500000, Avg. loss: 140.953492\n",
      "Total training time: 28.97 seconds.\n",
      "-- Epoch 176\n",
      "Norm: 157.04, NNZs: 683, Bias: -560.245921, T: 10560000, Avg. loss: 140.535713\n",
      "Total training time: 29.11 seconds.\n",
      "-- Epoch 177\n",
      "Norm: 156.13, NNZs: 683, Bias: -560.480999, T: 10620000, Avg. loss: 137.566905\n",
      "Total training time: 29.26 seconds.\n",
      "-- Epoch 178\n",
      "Norm: 155.87, NNZs: 683, Bias: -560.722283, T: 10680000, Avg. loss: 138.023845\n",
      "Total training time: 29.40 seconds.\n",
      "-- Epoch 179\n",
      "Norm: 155.36, NNZs: 683, Bias: -560.966882, T: 10740000, Avg. loss: 136.972390\n",
      "Total training time: 29.54 seconds.\n",
      "-- Epoch 180\n",
      "Norm: 154.95, NNZs: 683, Bias: -561.224038, T: 10800000, Avg. loss: 137.326018\n",
      "Total training time: 29.68 seconds.\n",
      "-- Epoch 181\n",
      "Norm: 154.84, NNZs: 683, Bias: -561.453913, T: 10860000, Avg. loss: 135.320133\n",
      "Total training time: 29.82 seconds.\n",
      "-- Epoch 182\n",
      "Norm: 153.59, NNZs: 683, Bias: -561.672467, T: 10920000, Avg. loss: 135.448423\n",
      "Total training time: 29.97 seconds.\n",
      "-- Epoch 183\n",
      "Norm: 152.56, NNZs: 683, Bias: -561.906248, T: 10980000, Avg. loss: 133.523083\n",
      "Total training time: 30.11 seconds.\n",
      "-- Epoch 184\n",
      "Norm: 151.91, NNZs: 683, Bias: -562.137840, T: 11040000, Avg. loss: 135.181586\n",
      "Total training time: 30.25 seconds.\n",
      "-- Epoch 185\n",
      "Norm: 151.22, NNZs: 683, Bias: -562.377166, T: 11100000, Avg. loss: 132.154813\n",
      "Total training time: 30.39 seconds.\n",
      "-- Epoch 186\n",
      "Norm: 150.71, NNZs: 683, Bias: -562.599969, T: 11160000, Avg. loss: 131.222433\n",
      "Total training time: 30.54 seconds.\n",
      "-- Epoch 187\n",
      "Norm: 150.56, NNZs: 683, Bias: -562.809944, T: 11220000, Avg. loss: 130.788216\n",
      "Total training time: 30.70 seconds.\n",
      "-- Epoch 188\n",
      "Norm: 149.74, NNZs: 683, Bias: -563.038366, T: 11280000, Avg. loss: 130.688515\n",
      "Total training time: 30.84 seconds.\n",
      "-- Epoch 189\n",
      "Norm: 149.39, NNZs: 683, Bias: -563.271745, T: 11340000, Avg. loss: 130.501665\n",
      "Total training time: 30.98 seconds.\n",
      "-- Epoch 190\n",
      "Norm: 148.96, NNZs: 684, Bias: -563.505653, T: 11400000, Avg. loss: 132.015050\n",
      "Total training time: 31.13 seconds.\n",
      "-- Epoch 191\n",
      "Norm: 148.22, NNZs: 684, Bias: -563.710341, T: 11460000, Avg. loss: 128.597867\n",
      "Total training time: 31.27 seconds.\n",
      "-- Epoch 192\n",
      "Norm: 147.64, NNZs: 684, Bias: -563.920907, T: 11520000, Avg. loss: 129.501696\n",
      "Total training time: 31.41 seconds.\n",
      "-- Epoch 193\n",
      "Norm: 147.07, NNZs: 684, Bias: -564.140819, T: 11580000, Avg. loss: 126.717734\n",
      "Total training time: 31.55 seconds.\n",
      "-- Epoch 194\n",
      "Norm: 146.46, NNZs: 684, Bias: -564.363864, T: 11640000, Avg. loss: 128.264965\n",
      "Total training time: 31.70 seconds.\n",
      "-- Epoch 195\n",
      "Norm: 146.14, NNZs: 684, Bias: -564.579772, T: 11700000, Avg. loss: 125.609126\n",
      "Total training time: 31.84 seconds.\n",
      "-- Epoch 196\n",
      "Norm: 145.21, NNZs: 684, Bias: -564.795452, T: 11760000, Avg. loss: 125.517663\n",
      "Total training time: 31.98 seconds.\n",
      "-- Epoch 197\n",
      "Norm: 144.43, NNZs: 684, Bias: -565.029527, T: 11820000, Avg. loss: 125.439432\n",
      "Total training time: 32.12 seconds.\n",
      "-- Epoch 198\n",
      "Norm: 144.09, NNZs: 684, Bias: -565.232053, T: 11880000, Avg. loss: 123.735564\n",
      "Total training time: 32.26 seconds.\n",
      "-- Epoch 199\n",
      "Norm: 143.69, NNZs: 684, Bias: -565.450352, T: 11940000, Avg. loss: 123.177567\n",
      "Total training time: 32.40 seconds.\n",
      "-- Epoch 200\n",
      "Norm: 143.05, NNZs: 684, Bias: -565.655828, T: 12000000, Avg. loss: 123.663105\n",
      "Total training time: 32.53 seconds.\n",
      "-- Epoch 201\n",
      "Norm: 142.69, NNZs: 684, Bias: -565.866956, T: 12060000, Avg. loss: 122.755855\n",
      "Total training time: 32.67 seconds.\n",
      "-- Epoch 202\n",
      "Norm: 142.07, NNZs: 684, Bias: -566.073751, T: 12120000, Avg. loss: 121.785790\n",
      "Total training time: 32.80 seconds.\n",
      "-- Epoch 203\n",
      "Norm: 141.92, NNZs: 684, Bias: -566.288540, T: 12180000, Avg. loss: 121.708955\n",
      "Total training time: 32.93 seconds.\n",
      "-- Epoch 204\n",
      "Norm: 141.29, NNZs: 684, Bias: -566.491622, T: 12240000, Avg. loss: 120.804166\n",
      "Total training time: 33.07 seconds.\n",
      "-- Epoch 205\n",
      "Norm: 140.78, NNZs: 684, Bias: -566.701884, T: 12300000, Avg. loss: 119.407007\n",
      "Total training time: 33.21 seconds.\n",
      "-- Epoch 206\n",
      "Norm: 140.00, NNZs: 684, Bias: -566.913576, T: 12360000, Avg. loss: 120.439940\n",
      "Total training time: 33.35 seconds.\n",
      "-- Epoch 207\n",
      "Norm: 139.67, NNZs: 684, Bias: -567.104050, T: 12420000, Avg. loss: 118.207725\n",
      "Total training time: 33.48 seconds.\n",
      "-- Epoch 208\n",
      "Norm: 139.54, NNZs: 684, Bias: -567.308834, T: 12480000, Avg. loss: 117.580985\n",
      "Total training time: 33.61 seconds.\n",
      "-- Epoch 209\n",
      "Norm: 138.96, NNZs: 684, Bias: -567.497450, T: 12540000, Avg. loss: 118.458840\n",
      "Total training time: 33.76 seconds.\n",
      "-- Epoch 210\n",
      "Norm: 138.02, NNZs: 684, Bias: -567.693152, T: 12600000, Avg. loss: 117.967523\n",
      "Total training time: 33.92 seconds.\n",
      "-- Epoch 211\n",
      "Norm: 137.56, NNZs: 684, Bias: -567.901381, T: 12660000, Avg. loss: 117.244541\n",
      "Total training time: 34.06 seconds.\n",
      "-- Epoch 212\n",
      "Norm: 137.03, NNZs: 684, Bias: -568.110179, T: 12720000, Avg. loss: 115.943512\n",
      "Total training time: 34.19 seconds.\n",
      "-- Epoch 213\n",
      "Norm: 136.54, NNZs: 684, Bias: -568.316434, T: 12780000, Avg. loss: 114.875313\n",
      "Total training time: 34.33 seconds.\n",
      "-- Epoch 214\n",
      "Norm: 136.24, NNZs: 684, Bias: -568.518600, T: 12840000, Avg. loss: 114.849565\n",
      "Total training time: 34.46 seconds.\n",
      "-- Epoch 215\n",
      "Norm: 135.69, NNZs: 684, Bias: -568.719849, T: 12900000, Avg. loss: 115.143610\n",
      "Total training time: 34.60 seconds.\n",
      "-- Epoch 216\n",
      "Norm: 135.17, NNZs: 684, Bias: -568.916270, T: 12960000, Avg. loss: 113.425134\n",
      "Total training time: 34.73 seconds.\n",
      "-- Epoch 217\n",
      "Norm: 135.25, NNZs: 684, Bias: -569.106390, T: 13020000, Avg. loss: 110.313752\n",
      "Total training time: 34.87 seconds.\n",
      "-- Epoch 218\n",
      "Norm: 134.08, NNZs: 684, Bias: -569.298703, T: 13080000, Avg. loss: 114.455483\n",
      "Total training time: 35.01 seconds.\n",
      "-- Epoch 219\n",
      "Norm: 134.27, NNZs: 684, Bias: -569.490921, T: 13140000, Avg. loss: 111.977868\n",
      "Total training time: 35.14 seconds.\n",
      "-- Epoch 220\n",
      "Norm: 134.02, NNZs: 684, Bias: -569.676196, T: 13200000, Avg. loss: 112.562630\n",
      "Total training time: 35.27 seconds.\n",
      "-- Epoch 221\n",
      "Norm: 133.41, NNZs: 684, Bias: -569.873471, T: 13260000, Avg. loss: 113.010206\n",
      "Total training time: 35.43 seconds.\n",
      "-- Epoch 222\n",
      "Norm: 133.11, NNZs: 684, Bias: -570.060783, T: 13320000, Avg. loss: 111.357299\n",
      "Total training time: 35.56 seconds.\n",
      "Convergence after 222 epochs took 35.56 seconds\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  5.0min finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42, verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "#training the model \n",
    "#and we would be using confusion matrix instead of accuracy\n",
    "sgd_clf=SGDClassifier(random_state=42, verbose=True)\n",
    "sgd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9902\n0.9929\n0.9711\n0.9656\n0.9766\n0.97\n0.9863\n0.9823\n0.9425\n0.9705\nNone\n"
     ]
    }
   ],
   "source": [
    "def calc_confusion_matrix(mtx):\n",
    "    for i in range(len(mtx)):\n",
    "        print(mtx[i].trace()/mtx[i].sum())\n",
    "\n",
    "y_pred=sgd_clf.predict(X_test)\n",
    "conf_mtx=multilabel_confusion_matrix(y_test, y_pred)\n",
    "print(calc_confusion_matrix(conf_mtx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0, NNZs: 618, Bias: -293.377224, T: 40000, Avg. loss: 165009.406008\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6065.82, NNZs: 632, Bias: -332.785343, T: 80000, Avg. loss: 26037.374952\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4337.21, NNZs: 644, Bias: -355.867186, T: 120000, Avg. loss: 15377.353117\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3577.46, NNZs: 644, Bias: -370.276294, T: 160000, Avg. loss: 10799.427330\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3068.14, NNZs: 650, Bias: -381.640576, T: 200000, Avg. loss: 8289.794416\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2645.66, NNZs: 656, Bias: -390.884517, T: 240000, Avg. loss: 6928.424365\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2373.38, NNZs: 660, Bias: -398.576650, T: 280000, Avg. loss: 5705.380962\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2143.42, NNZs: 660, Bias: -405.684948, T: 320000, Avg. loss: 5109.457734\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1993.20, NNZs: 660, Bias: -411.698322, T: 360000, Avg. loss: 4430.246685\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1829.70, NNZs: 660, Bias: -417.192325, T: 400000, Avg. loss: 3994.923112\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1709.88, NNZs: 661, Bias: -421.938512, T: 440000, Avg. loss: 3564.369756\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1611.39, NNZs: 664, Bias: -426.496846, T: 480000, Avg. loss: 3283.139964\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1496.49, NNZs: 664, Bias: -430.467610, T: 520000, Avg. loss: 2981.559042\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1411.03, NNZs: 667, Bias: -434.547453, T: 560000, Avg. loss: 2867.646496\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1344.85, NNZs: 667, Bias: -438.029201, T: 600000, Avg. loss: 2600.182997\n",
      "Total training time: 1.62 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1290.62, NNZs: 667, Bias: -441.265028, T: 640000, Avg. loss: 2419.217653\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1217.42, NNZs: 668, Bias: -444.287768, T: 680000, Avg. loss: 2263.204923\n",
      "Total training time: 1.84 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1185.03, NNZs: 668, Bias: -447.284640, T: 720000, Avg. loss: 2160.011432\n",
      "Total training time: 1.95 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1160.57, NNZs: 668, Bias: -449.822363, T: 760000, Avg. loss: 2014.752336\n",
      "Total training time: 2.05 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1105.76, NNZs: 668, Bias: -452.412305, T: 800000, Avg. loss: 1927.009624\n",
      "Total training time: 2.16 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1062.62, NNZs: 668, Bias: -454.886495, T: 840000, Avg. loss: 1850.448861\n",
      "Total training time: 2.26 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1025.63, NNZs: 670, Bias: -457.360039, T: 880000, Avg. loss: 1775.630058\n",
      "Total training time: 2.37 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 986.97, NNZs: 670, Bias: -459.570242, T: 920000, Avg. loss: 1654.201699\n",
      "Total training time: 2.48 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 960.30, NNZs: 670, Bias: -461.719300, T: 960000, Avg. loss: 1587.779889\n",
      "Total training time: 2.59 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 933.27, NNZs: 670, Bias: -463.735925, T: 1000000, Avg. loss: 1518.298353\n",
      "Total training time: 2.70 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 906.35, NNZs: 670, Bias: -465.804272, T: 1040000, Avg. loss: 1482.832954\n",
      "Total training time: 2.80 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 885.41, NNZs: 670, Bias: -467.698657, T: 1080000, Avg. loss: 1420.800267\n",
      "Total training time: 2.91 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 860.30, NNZs: 670, Bias: -469.545819, T: 1120000, Avg. loss: 1378.180698\n",
      "Total training time: 3.02 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 837.93, NNZs: 670, Bias: -471.254503, T: 1160000, Avg. loss: 1326.533589\n",
      "Total training time: 3.13 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 817.34, NNZs: 670, Bias: -472.880614, T: 1200000, Avg. loss: 1269.555197\n",
      "Total training time: 3.24 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 800.13, NNZs: 672, Bias: -474.566392, T: 1240000, Avg. loss: 1213.054428\n",
      "Total training time: 3.34 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 780.83, NNZs: 672, Bias: -476.130252, T: 1280000, Avg. loss: 1207.267573\n",
      "Total training time: 3.45 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 763.80, NNZs: 673, Bias: -477.681731, T: 1320000, Avg. loss: 1129.939023\n",
      "Total training time: 3.56 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 747.56, NNZs: 673, Bias: -479.224438, T: 1360000, Avg. loss: 1104.692640\n",
      "Total training time: 3.67 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 731.03, NNZs: 673, Bias: -480.695201, T: 1400000, Avg. loss: 1103.505460\n",
      "Total training time: 3.78 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 708.15, NNZs: 673, Bias: -482.136704, T: 1440000, Avg. loss: 1065.514482\n",
      "Total training time: 3.88 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 700.93, NNZs: 674, Bias: -483.566975, T: 1480000, Avg. loss: 1024.317449\n",
      "Total training time: 3.99 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 682.35, NNZs: 674, Bias: -484.839548, T: 1520000, Avg. loss: 1006.129585\n",
      "Total training time: 4.10 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 672.89, NNZs: 674, Bias: -486.254134, T: 1560000, Avg. loss: 976.256169\n",
      "Total training time: 4.21 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 664.57, NNZs: 674, Bias: -487.563830, T: 1600000, Avg. loss: 958.807552\n",
      "Total training time: 4.32 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 652.96, NNZs: 674, Bias: -488.804385, T: 1640000, Avg. loss: 922.099761\n",
      "Total training time: 4.42 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 640.91, NNZs: 674, Bias: -490.002275, T: 1680000, Avg. loss: 894.963841\n",
      "Total training time: 4.53 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 632.91, NNZs: 674, Bias: -491.188975, T: 1720000, Avg. loss: 881.814948\n",
      "Total training time: 4.64 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 623.00, NNZs: 674, Bias: -492.325704, T: 1760000, Avg. loss: 864.503501\n",
      "Total training time: 4.75 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 620.51, NNZs: 674, Bias: -493.381232, T: 1800000, Avg. loss: 829.590154\n",
      "Total training time: 4.86 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 607.51, NNZs: 674, Bias: -494.478452, T: 1840000, Avg. loss: 827.458509\n",
      "Total training time: 4.96 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 598.39, NNZs: 674, Bias: -495.542838, T: 1880000, Avg. loss: 793.772931\n",
      "Total training time: 5.07 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 586.15, NNZs: 674, Bias: -496.642796, T: 1920000, Avg. loss: 798.227160\n",
      "Total training time: 5.18 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 575.11, NNZs: 674, Bias: -497.709318, T: 1960000, Avg. loss: 783.647023\n",
      "Total training time: 5.29 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 567.43, NNZs: 675, Bias: -498.713685, T: 2000000, Avg. loss: 739.080819\n",
      "Total training time: 5.40 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 559.61, NNZs: 675, Bias: -499.707627, T: 2040000, Avg. loss: 749.509818\n",
      "Total training time: 5.50 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 551.64, NNZs: 675, Bias: -500.658771, T: 2080000, Avg. loss: 734.855738\n",
      "Total training time: 5.61 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 540.05, NNZs: 675, Bias: -501.596452, T: 2120000, Avg. loss: 719.948045\n",
      "Total training time: 5.72 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 536.15, NNZs: 675, Bias: -502.503057, T: 2160000, Avg. loss: 680.677098\n",
      "Total training time: 5.83 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 529.13, NNZs: 675, Bias: -503.374486, T: 2200000, Avg. loss: 684.295135\n",
      "Total training time: 5.93 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 520.18, NNZs: 675, Bias: -504.256770, T: 2240000, Avg. loss: 667.597605\n",
      "Total training time: 6.04 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 513.60, NNZs: 675, Bias: -505.136199, T: 2280000, Avg. loss: 654.070841\n",
      "Total training time: 6.15 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 505.61, NNZs: 675, Bias: -505.944387, T: 2320000, Avg. loss: 649.829077\n",
      "Total training time: 6.25 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 502.24, NNZs: 675, Bias: -506.815800, T: 2360000, Avg. loss: 634.049071\n",
      "Total training time: 6.36 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 491.13, NNZs: 675, Bias: -507.601471, T: 2400000, Avg. loss: 626.255230\n",
      "Total training time: 6.47 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 488.61, NNZs: 675, Bias: -508.443814, T: 2440000, Avg. loss: 617.212047\n",
      "Total training time: 6.57 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 480.47, NNZs: 675, Bias: -509.236154, T: 2480000, Avg. loss: 609.064414\n",
      "Total training time: 6.68 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 477.49, NNZs: 675, Bias: -510.059869, T: 2520000, Avg. loss: 585.103701\n",
      "Total training time: 6.79 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 471.03, NNZs: 675, Bias: -510.779763, T: 2560000, Avg. loss: 590.056622\n",
      "Total training time: 6.90 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 464.74, NNZs: 675, Bias: -511.515477, T: 2600000, Avg. loss: 573.169546\n",
      "Total training time: 7.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 459.05, NNZs: 675, Bias: -512.270848, T: 2640000, Avg. loss: 582.010987\n",
      "Total training time: 7.11 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 454.27, NNZs: 675, Bias: -513.007425, T: 2680000, Avg. loss: 557.033887\n",
      "Total training time: 7.22 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 447.34, NNZs: 675, Bias: -513.710651, T: 2720000, Avg. loss: 553.266575\n",
      "Total training time: 7.33 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 444.12, NNZs: 675, Bias: -514.414640, T: 2760000, Avg. loss: 540.223445\n",
      "Total training time: 7.44 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 439.21, NNZs: 675, Bias: -515.105377, T: 2800000, Avg. loss: 536.358621\n",
      "Total training time: 7.55 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 436.26, NNZs: 675, Bias: -515.786110, T: 2840000, Avg. loss: 528.005314\n",
      "Total training time: 7.65 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 432.80, NNZs: 675, Bias: -516.453693, T: 2880000, Avg. loss: 523.429734\n",
      "Total training time: 7.76 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 427.87, NNZs: 675, Bias: -517.136728, T: 2920000, Avg. loss: 512.099529\n",
      "Total training time: 7.87 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 423.51, NNZs: 675, Bias: -517.762376, T: 2960000, Avg. loss: 501.773458\n",
      "Total training time: 7.97 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 421.05, NNZs: 675, Bias: -518.383266, T: 3000000, Avg. loss: 511.283473\n",
      "Total training time: 8.08 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 417.89, NNZs: 675, Bias: -519.025394, T: 3040000, Avg. loss: 496.052766\n",
      "Total training time: 8.19 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 411.48, NNZs: 675, Bias: -519.675380, T: 3080000, Avg. loss: 502.336985\n",
      "Total training time: 8.30 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 407.22, NNZs: 675, Bias: -520.304338, T: 3120000, Avg. loss: 483.465041\n",
      "Total training time: 8.40 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 404.22, NNZs: 675, Bias: -520.953782, T: 3160000, Avg. loss: 469.217688\n",
      "Total training time: 8.51 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 400.54, NNZs: 675, Bias: -521.585398, T: 3200000, Avg. loss: 468.429811\n",
      "Total training time: 8.62 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 398.80, NNZs: 675, Bias: -522.162672, T: 3240000, Avg. loss: 455.982705\n",
      "Total training time: 8.73 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 393.41, NNZs: 675, Bias: -522.776001, T: 3280000, Avg. loss: 453.834974\n",
      "Total training time: 8.83 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 389.96, NNZs: 675, Bias: -523.348568, T: 3320000, Avg. loss: 452.664953\n",
      "Total training time: 8.94 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 384.93, NNZs: 675, Bias: -523.929282, T: 3360000, Avg. loss: 439.723704\n",
      "Total training time: 9.05 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 383.52, NNZs: 675, Bias: -524.523687, T: 3400000, Avg. loss: 436.699082\n",
      "Total training time: 9.16 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 381.39, NNZs: 675, Bias: -525.120075, T: 3440000, Avg. loss: 429.130419\n",
      "Total training time: 9.26 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 379.26, NNZs: 675, Bias: -525.672117, T: 3480000, Avg. loss: 430.072382\n",
      "Total training time: 9.37 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 376.08, NNZs: 675, Bias: -526.257380, T: 3520000, Avg. loss: 430.567189\n",
      "Total training time: 9.48 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 374.44, NNZs: 675, Bias: -526.796886, T: 3560000, Avg. loss: 416.501766\n",
      "Total training time: 9.59 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 369.93, NNZs: 675, Bias: -527.349781, T: 3600000, Avg. loss: 417.108099\n",
      "Total training time: 9.70 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 367.59, NNZs: 675, Bias: -527.874481, T: 3640000, Avg. loss: 412.693740\n",
      "Total training time: 9.81 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 365.84, NNZs: 675, Bias: -528.388024, T: 3680000, Avg. loss: 408.578799\n",
      "Total training time: 9.92 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 361.93, NNZs: 675, Bias: -528.901327, T: 3720000, Avg. loss: 403.493918\n",
      "Total training time: 10.02 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 360.08, NNZs: 675, Bias: -529.411820, T: 3760000, Avg. loss: 384.767101\n",
      "Total training time: 10.13 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 357.99, NNZs: 675, Bias: -529.911603, T: 3800000, Avg. loss: 395.350960\n",
      "Total training time: 10.24 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 354.76, NNZs: 675, Bias: -530.429638, T: 3840000, Avg. loss: 387.324753\n",
      "Total training time: 10.35 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 351.81, NNZs: 675, Bias: -530.926811, T: 3880000, Avg. loss: 386.612091\n",
      "Total training time: 10.46 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 350.55, NNZs: 675, Bias: -531.342181, T: 3920000, Avg. loss: 371.931627\n",
      "Total training time: 10.57 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 347.74, NNZs: 675, Bias: -531.816582, T: 3960000, Avg. loss: 373.969482\n",
      "Total training time: 10.68 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 345.14, NNZs: 675, Bias: -532.321360, T: 4000000, Avg. loss: 371.332966\n",
      "Total training time: 10.78 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 342.71, NNZs: 675, Bias: -532.811201, T: 4040000, Avg. loss: 370.060454\n",
      "Total training time: 10.89 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 341.11, NNZs: 675, Bias: -533.264305, T: 4080000, Avg. loss: 364.037661\n",
      "Total training time: 11.00 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 337.95, NNZs: 675, Bias: -533.703240, T: 4120000, Avg. loss: 357.660824\n",
      "Total training time: 11.11 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 333.68, NNZs: 675, Bias: -534.140340, T: 4160000, Avg. loss: 361.340372\n",
      "Total training time: 11.21 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 332.80, NNZs: 675, Bias: -534.611487, T: 4200000, Avg. loss: 353.631497\n",
      "Total training time: 11.32 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 329.54, NNZs: 675, Bias: -535.059341, T: 4240000, Avg. loss: 349.077557\n",
      "Total training time: 11.43 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 328.68, NNZs: 675, Bias: -535.505280, T: 4280000, Avg. loss: 344.014158\n",
      "Total training time: 11.53 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 327.28, NNZs: 675, Bias: -535.960962, T: 4320000, Avg. loss: 345.007371\n",
      "Total training time: 11.64 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 325.01, NNZs: 675, Bias: -536.426225, T: 4360000, Avg. loss: 344.860473\n",
      "Total training time: 11.75 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 322.38, NNZs: 675, Bias: -536.873558, T: 4400000, Avg. loss: 335.463343\n",
      "Total training time: 11.86 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 320.71, NNZs: 675, Bias: -537.328230, T: 4440000, Avg. loss: 335.133249\n",
      "Total training time: 11.97 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 319.13, NNZs: 675, Bias: -537.767505, T: 4480000, Avg. loss: 332.264424\n",
      "Total training time: 12.07 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 317.12, NNZs: 675, Bias: -538.203035, T: 4520000, Avg. loss: 330.801605\n",
      "Total training time: 12.18 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 314.69, NNZs: 675, Bias: -538.634657, T: 4560000, Avg. loss: 323.048707\n",
      "Total training time: 12.29 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 312.84, NNZs: 675, Bias: -539.060258, T: 4600000, Avg. loss: 325.050731\n",
      "Total training time: 12.40 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 310.53, NNZs: 675, Bias: -539.477962, T: 4640000, Avg. loss: 317.839221\n",
      "Total training time: 12.50 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 307.67, NNZs: 675, Bias: -539.896281, T: 4680000, Avg. loss: 317.385115\n",
      "Total training time: 12.61 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 306.93, NNZs: 675, Bias: -540.272653, T: 4720000, Avg. loss: 315.926531\n",
      "Total training time: 12.72 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 304.64, NNZs: 675, Bias: -540.671236, T: 4760000, Avg. loss: 316.095734\n",
      "Total training time: 12.85 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 303.87, NNZs: 675, Bias: -541.064364, T: 4800000, Avg. loss: 305.806702\n",
      "Total training time: 12.95 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 303.06, NNZs: 675, Bias: -541.493728, T: 4840000, Avg. loss: 312.675294\n",
      "Total training time: 13.06 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 299.33, NNZs: 676, Bias: -541.901081, T: 4880000, Avg. loss: 311.553205\n",
      "Total training time: 13.17 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 296.77, NNZs: 676, Bias: -542.266305, T: 4920000, Avg. loss: 302.406036\n",
      "Total training time: 13.27 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 294.95, NNZs: 676, Bias: -542.675135, T: 4960000, Avg. loss: 300.570777\n",
      "Total training time: 13.38 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 293.52, NNZs: 676, Bias: -543.054626, T: 5000000, Avg. loss: 288.331633\n",
      "Total training time: 13.50 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 292.79, NNZs: 676, Bias: -543.397147, T: 5040000, Avg. loss: 293.529128\n",
      "Total training time: 13.61 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 291.27, NNZs: 677, Bias: -543.778426, T: 5080000, Avg. loss: 292.885567\n",
      "Total training time: 13.72 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 289.42, NNZs: 677, Bias: -544.164673, T: 5120000, Avg. loss: 289.454059\n",
      "Total training time: 13.83 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 287.60, NNZs: 677, Bias: -544.524461, T: 5160000, Avg. loss: 289.415702\n",
      "Total training time: 13.94 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 285.19, NNZs: 677, Bias: -544.910472, T: 5200000, Avg. loss: 287.686404\n",
      "Total training time: 14.04 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 283.91, NNZs: 677, Bias: -545.268681, T: 5240000, Avg. loss: 282.974804\n",
      "Total training time: 14.15 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 282.50, NNZs: 677, Bias: -545.627845, T: 5280000, Avg. loss: 277.305165\n",
      "Total training time: 14.26 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 281.35, NNZs: 677, Bias: -546.005090, T: 5320000, Avg. loss: 278.538563\n",
      "Total training time: 14.37 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 279.34, NNZs: 677, Bias: -546.370173, T: 5360000, Avg. loss: 279.037227\n",
      "Total training time: 14.47 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 278.71, NNZs: 677, Bias: -546.706529, T: 5400000, Avg. loss: 270.469934\n",
      "Total training time: 14.58 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 276.91, NNZs: 677, Bias: -547.071738, T: 5440000, Avg. loss: 270.756717\n",
      "Total training time: 14.69 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 274.27, NNZs: 677, Bias: -547.395904, T: 5480000, Avg. loss: 270.802239\n",
      "Total training time: 14.80 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 273.65, NNZs: 677, Bias: -547.721315, T: 5520000, Avg. loss: 262.084316\n",
      "Total training time: 14.91 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 272.57, NNZs: 677, Bias: -548.053378, T: 5560000, Avg. loss: 262.835821\n",
      "Total training time: 15.02 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 272.86, NNZs: 677, Bias: -548.379458, T: 5600000, Avg. loss: 264.203417\n",
      "Total training time: 15.13 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 271.64, NNZs: 677, Bias: -548.703249, T: 5640000, Avg. loss: 265.568671\n",
      "Total training time: 15.24 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 270.02, NNZs: 677, Bias: -549.028233, T: 5680000, Avg. loss: 254.655746\n",
      "Total training time: 15.35 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 268.66, NNZs: 677, Bias: -549.361571, T: 5720000, Avg. loss: 258.264301\n",
      "Total training time: 15.46 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 266.87, NNZs: 677, Bias: -549.695970, T: 5760000, Avg. loss: 259.191184\n",
      "Total training time: 15.57 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 265.45, NNZs: 677, Bias: -550.041961, T: 5800000, Avg. loss: 254.523911\n",
      "Total training time: 15.68 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 264.00, NNZs: 677, Bias: -550.363178, T: 5840000, Avg. loss: 255.765815\n",
      "Total training time: 15.79 seconds.\n",
      "-- Epoch 147\n",
      "Norm: 262.99, NNZs: 677, Bias: -550.668599, T: 5880000, Avg. loss: 248.550381\n",
      "Total training time: 15.90 seconds.\n",
      "-- Epoch 148\n",
      "Norm: 261.65, NNZs: 677, Bias: -551.004171, T: 5920000, Avg. loss: 250.851143\n",
      "Total training time: 16.01 seconds.\n",
      "-- Epoch 149\n",
      "Norm: 260.55, NNZs: 677, Bias: -551.323961, T: 5960000, Avg. loss: 246.164471\n",
      "Total training time: 16.12 seconds.\n",
      "-- Epoch 150\n",
      "Norm: 258.85, NNZs: 677, Bias: -551.629912, T: 6000000, Avg. loss: 245.075289\n",
      "Total training time: 16.22 seconds.\n",
      "-- Epoch 151\n",
      "Norm: 258.62, NNZs: 677, Bias: -551.932200, T: 6040000, Avg. loss: 247.265796\n",
      "Total training time: 16.33 seconds.\n",
      "-- Epoch 152\n",
      "Norm: 257.36, NNZs: 677, Bias: -552.230859, T: 6080000, Avg. loss: 241.514702\n",
      "Total training time: 16.44 seconds.\n",
      "-- Epoch 153\n",
      "Norm: 256.57, NNZs: 677, Bias: -552.509531, T: 6120000, Avg. loss: 231.627536\n",
      "Total training time: 16.55 seconds.\n",
      "-- Epoch 154\n",
      "Norm: 254.94, NNZs: 677, Bias: -552.817248, T: 6160000, Avg. loss: 239.228443\n",
      "Total training time: 16.66 seconds.\n",
      "-- Epoch 155\n",
      "Norm: 253.74, NNZs: 677, Bias: -553.113271, T: 6200000, Avg. loss: 239.405647\n",
      "Total training time: 16.77 seconds.\n",
      "-- Epoch 156\n",
      "Norm: 252.58, NNZs: 677, Bias: -553.415488, T: 6240000, Avg. loss: 242.200841\n",
      "Total training time: 16.88 seconds.\n",
      "-- Epoch 157\n",
      "Norm: 251.32, NNZs: 677, Bias: -553.720549, T: 6280000, Avg. loss: 233.721197\n",
      "Total training time: 16.99 seconds.\n",
      "-- Epoch 158\n",
      "Norm: 249.87, NNZs: 677, Bias: -554.015734, T: 6320000, Avg. loss: 232.190539\n",
      "Total training time: 17.10 seconds.\n",
      "Convergence after 158 epochs took 17.10 seconds\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  2.7min finished\n"
     ]
    }
   ],
   "source": [
    "y_preds=cross_val_predict(sgd_clf, X_train, y_train, cv=3,method=\"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9894\n0.9893\n0.9726\n0.97145\n0.97565\n0.9640833333333333\n0.9852166666666666\n0.9704\n0.9616\n0.9542333333333334\nNone\n"
     ]
    }
   ],
   "source": [
    "#whatever the result maybe for the cross_val_predict\n",
    "#lets calc its conf mtx\n",
    "print(calc_confusion_matrix(multilabel_confusion_matrix(y_train, y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8669666666666667\n",
      "0.8669666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "print(precision_score(y_train, y_preds, average='micro'))\n",
    "print(recall_score(y_train, y_preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}